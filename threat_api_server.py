from fastapi import FastAPI, File, UploadFile, HTTPException, BackgroundTasks
from fastapi.responses import JSONResponse, FileResponse
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel
from typing import List, Dict, Any, Optional
import json
import os
import tempfile
import asyncio
from datetime import datetime, timezone, timedelta
import logging
from pathlib import Path

# ê¸°ì¡´ ë°ì´í„° ì²˜ë¦¬ ì‹œìŠ¤í…œ import
from C_part_data_pipeline import MultiFormatThreatNormalizer, ThreatProcessingSystem

# FastAPI ì•± ì´ˆê¸°í™”
app = FastAPI(
    title="ìœ„í˜‘ì •ë³´ ë°ì´í„° ì •ì œ API",
    description="AíŒŒíŠ¸(ë‹¤í¬ì›¹), BíŒŒíŠ¸(í…”ë ˆê·¸ë¨) ë°ì´í„°ë¥¼ ìˆ˜ì§‘í•˜ì—¬ DíŒŒíŠ¸(ëŒ€ì‹œë³´ë“œ)ìš© í†µí•© DB ì œê³µ",
    version="1.0.0"
)
def get_kst_time():
    """í•œêµ­ ì‹œê°„ ë°˜í™˜"""
    kst = timezone(timedelta(hours=9))
    return datetime.now(kst).strftime('%Y-%m-%d %H:%M:%S')

# CORS ì„¤ì • (ë‹¤ë¥¸ íŒŒíŠ¸ì—ì„œ ì ‘ê·¼ ê°€ëŠ¥í•˜ë„ë¡)
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],  # í”„ë¡œë•ì…˜ì—ì„œëŠ” íŠ¹ì • ë„ë©”ì¸ë§Œ í—ˆìš©
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# ê¸€ë¡œë²Œ ë³€ìˆ˜ ì´ˆê¸°í™” - ê¸°ì¡´ íŒŒì´í”„ë¼ì¸ê³¼ ë™ì¼í•œ DB ì‚¬ìš©
DB_PATH = os.getenv('DB_PATH', './persistent/threat_intelligence.db')

# ğŸ”¥ ì¶”ê°€: ë””ë ‰í† ë¦¬ ìƒì„±
persistent_dir = os.path.dirname(DB_PATH)
os.makedirs(persistent_dir, exist_ok=True)
print(f"ë°ì´í„°ë² ì´ìŠ¤ ê²½ë¡œ: {DB_PATH}")
print(f"ì˜êµ¬ ì €ì¥ì†Œ ë””ë ‰í† ë¦¬ ìƒì„±: {persistent_dir}")

normalizer = MultiFormatThreatNormalizer(
    output_folder='api_processed_data',
    db_path=DB_PATH
)
threat_processor = ThreatProcessingSystem(DB_PATH)

# ë¡œê¹… ì„¤ì •
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# =============================================================================
# Pydantic ëª¨ë¸ë“¤ (API ìš”ì²­/ì‘ë‹µ êµ¬ì¡° ì •ì˜)
# =============================================================================

class ThreatDataItem(BaseModel):
    """ë‹¨ì¼ ìœ„í˜‘ì •ë³´ ë°ì´í„° í•­ëª©"""
    source_type: Optional[str] = None
    thread_id: Optional[str] = None
    url: Optional[str] = None
    keyword: Optional[str] = None
    found_at: Optional[str] = None
    title: Optional[str] = None
    text: Optional[str] = None
    author: Optional[str] = None
    date: Optional[str] = None
    threat_type: Optional[str] = None
    platform: Optional[str] = None
    event_id: Optional[str] = None
    event_info: Optional[str] = None
    event_date: Optional[str] = None
    pii_data: Optional[Dict[str, Any]] = None

class BulkThreatData(BaseModel):
    """ëŒ€ëŸ‰ ìœ„í˜‘ì •ë³´ ë°ì´í„°"""
    source: str  # 'darkweb' ë˜ëŠ” 'telegram'
    data: List[Dict[str, Any]]

class ProcessingResponse(BaseModel):
    """ì²˜ë¦¬ ê²°ê³¼ ì‘ë‹µ"""
    success: bool
    message: str
    processed_count: int
    new_posts: int
    related_posts: int
    duplicates: int
    errors: int
    batch_id: Optional[str] = None

class SearchRequest(BaseModel):
    """ê²€ìƒ‰ ìš”ì²­"""
    query: str
    search_type: str  # 'ioc', 'author', 'content'
    limit: Optional[int] = 100

# =============================================================================
# AíŒŒíŠ¸, BíŒŒíŠ¸ìš© ë°ì´í„° ìˆ˜ì§‘ ì—”ë“œí¬ì¸íŠ¸
# =============================================================================

@app.post("/api/v1/data/upload/json", response_model=ProcessingResponse)
async def upload_json_data(
    background_tasks: BackgroundTasks,
    file: UploadFile = File(...),
    source: str = "unknown"
):
    """
    AíŒŒíŠ¸, BíŒŒíŠ¸ì—ì„œ JSON íŒŒì¼ ì—…ë¡œë“œ
    """
    try:
        # íŒŒì¼ í˜•ì‹ ê²€ì¦
        if not file.filename.endswith('.json'):
            raise HTTPException(status_code=400, detail="JSON íŒŒì¼ë§Œ ì—…ë¡œë“œ ê°€ëŠ¥í•©ë‹ˆë‹¤")
        
        # ì„ì‹œ íŒŒì¼ë¡œ ì €ì¥
        with tempfile.NamedTemporaryFile(mode='wb', suffix='.json', delete=False) as temp_file:
            content = await file.read()
            temp_file.write(content)
            temp_file_path = temp_file.name
        
        # ë°±ê·¸ë¼ìš´ë“œì—ì„œ ì²˜ë¦¬
        background_tasks.add_task(process_uploaded_file, temp_file_path, source, file.filename)
        
        logger.info(f"JSON íŒŒì¼ ì—…ë¡œë“œ ì™„ë£Œ: {file.filename} (ì†ŒìŠ¤: {source})")
        
        return ProcessingResponse(
            success=True,
            message=f"íŒŒì¼ ì—…ë¡œë“œ ì™„ë£Œ. ë°±ê·¸ë¼ìš´ë“œì—ì„œ ì²˜ë¦¬ ì¤‘ì…ë‹ˆë‹¤.",
            processed_count=0,  # ë°±ê·¸ë¼ìš´ë“œ ì²˜ë¦¬ì´ë¯€ë¡œ ì•„ì§ ëª¨ë¦„
            new_posts=0,
            related_posts=0,
            duplicates=0,
            errors=0
        )
        
    except Exception as e:
        logger.error(f"JSON ì—…ë¡œë“œ ì˜¤ë¥˜: {e}")
        raise HTTPException(status_code=500, detail=f"íŒŒì¼ ì²˜ë¦¬ ì˜¤ë¥˜: {str(e)}")

@app.post("/api/v1/data/upload/bulk", response_model=ProcessingResponse)
async def upload_bulk_data(data: BulkThreatData):
    """
    AíŒŒíŠ¸, BíŒŒíŠ¸ì—ì„œ JSON ë°ì´í„°ë¥¼ ì§ì ‘ POSTë¡œ ì „ì†¡
    """
    try:
        #ì†ŒìŠ¤ íƒ€ì… ê²€ì¦ 
        valid_sources = ['darkweb', 'telegram', 'misp']  #misp ì¶”ê°€
        if data.source not in valid_sources:
            raise HTTPException(status_code=400, detail=f"ì§€ì›ë˜ì§€ ì•ŠëŠ” ì†ŒìŠ¤ íƒ€ì…: {data.source}")
        
        # ğŸ”¥ ëŒ€ëŸ‰ ë°ì´í„°ë¥¼ ì‘ì€ ë°°ì¹˜ë¡œ ë‚˜ëˆ„ê¸°
        batch_size = 50  # í•œ ë²ˆì— 50ê°œì”©ë§Œ ì²˜ë¦¬
        total_items = len(data.data)

        logger.info(f"ëŒ€ëŸ‰ ë°ì´í„° ìˆ˜ì‹ : {len(data.data)}ê°œ í•­ëª© (ì†ŒìŠ¤: {data.source})")
        logger.info(f"ë°°ì¹˜ í¬ê¸°: {batch_size}ê°œì”© ì²˜ë¦¬")
        
        all_stats = {'saved': 0, 'duplicates': 0, 'errors': 0}

        for i in range(0, total_items, batch_size):
            batch_data = data.data[i:i + batch_size]
            logger.info(f"ë°°ì¹˜ ì²˜ë¦¬ ì¤‘: {i+1}-{min(i+batch_size, total_items)}/{total_items}")        
            
            # ë°ì´í„° ì •ì œ ë° í‘œì¤€í™”
            normalized_data = []
            for item in batch_data:
                normalized_item = normalizer.normalize_single_item(item)
                # ì†ŒìŠ¤ íƒ€ì… ê°•ì œ ì„¤ì • (AíŒŒíŠ¸: darkweb, BíŒŒíŠ¸: telegram)
                normalized_item['source_type'] = data.source
                normalized_data.append(normalized_item)
            
            # ë°ì´í„°ë² ì´ìŠ¤ì— ì €ì¥ (ì—°ê´€ê´€ê³„ ë¶„ì„ í¬í•¨)
            stats = normalizer.save_to_database(normalized_data)
            all_stats['saved'] += stats.get('saved', 0)
            all_stats['duplicates'] += stats.get('duplicates', 0)
            all_stats['errors'] += stats.get('errors', 0)

            if i + batch_size < total_items:
                await asyncio.sleep(2)
                logger.info(f"ë°°ì¹˜ íœ´ì‹ : 2ì´ˆ")
                
            logger.info(f"ë°°ì¹˜ {i // batch_size + 1} ì²˜ë¦¬ ì™„ë£Œ: {stats}")
        
        logger.info(f"ì „ì²´ ëŒ€ëŸ‰ ë°ì´í„° ì²˜ë¦¬ ì™„ë£Œ: {all_stats}")
        
        return ProcessingResponse(
            success=True,
            message="ë°ì´í„° ì²˜ë¦¬ ì™„ë£Œ",
            processed_count=total_items,
            new_posts=all_stats.get('saved', 0),
            related_posts=0,
            duplicates=all_stats.get('duplicates', 0),
            errors=all_stats.get('errors', 0)
        )
        
    except Exception as e:
        logger.error(f"ëŒ€ëŸ‰ ë°ì´í„° ì²˜ë¦¬ ì˜¤ë¥˜: {e}")
        raise HTTPException(status_code=500, detail=f"ë°ì´í„° ì²˜ë¦¬ ì˜¤ë¥˜: {str(e)}")

@app.post("/api/v1/data/upload/single")
async def upload_single_data(item: ThreatDataItem):
    """
    ë‹¨ì¼ ìœ„í˜‘ì •ë³´ ë°ì´í„° ì—…ë¡œë“œ (í…ŒìŠ¤íŠ¸ìš©)
    """
    try:
        # Pydantic ëª¨ë¸ì„ ë”•ì…”ë„ˆë¦¬ë¡œ ë³€í™˜
        item_dict = item.dict()
        
        # ì •ì œ ë° í‘œì¤€í™”
        normalized_item = normalizer.normalize_single_item(item_dict)
        
        # ë°ì´í„°ë² ì´ìŠ¤ì— ì €ì¥
        stats = normalizer.save_to_database([normalized_item])
        
        return {
            "success": True,
            "message": "ë‹¨ì¼ ë°ì´í„° ì €ì¥ ì™„ë£Œ",
            "stats": stats
        }
        
    except Exception as e:
        logger.error(f"ë‹¨ì¼ ë°ì´í„° ì²˜ë¦¬ ì˜¤ë¥˜: {e}")
        raise HTTPException(status_code=500, detail=f"ë°ì´í„° ì²˜ë¦¬ ì˜¤ë¥˜: {str(e)}")

# =============================================================================
# DíŒŒíŠ¸ìš© ë°ì´í„° ì¡°íšŒ ì—”ë“œí¬ì¸íŠ¸
# =============================================================================

@app.get("/api/v1/data/stats")
async def get_database_stats():
    """
    DíŒŒíŠ¸ìš© ë°ì´í„°ë² ì´ìŠ¤ ì „ì²´ í†µê³„ ì œê³µ
    """
    try:
        stats = normalizer.get_database_stats()
        return {
            "success": True,
            "data": stats,
            "timestamp": datetime.now().isoformat()
        }
    except Exception as e:
        logger.error(f"í†µê³„ ì¡°íšŒ ì˜¤ë¥˜: {e}")
        raise HTTPException(status_code=500, detail=f"í†µê³„ ì¡°íšŒ ì˜¤ë¥˜: {str(e)}")

@app.post("/api/v1/data/search")
async def search_threat_data(request: SearchRequest):
    """
    DíŒŒíŠ¸ìš© ìœ„í˜‘ì •ë³´ ê²€ìƒ‰ API
    """
    try:
        if request.search_type == "ioc":
            # IOC ê²€ìƒ‰
            results = threat_processor.search_ioc_with_relations(
                request.query, 
                ioc_type=None
            )
        elif request.search_type == "author":
            # ì‘ì„±ì ê²€ìƒ‰
            results = threat_processor.search_by_author_with_timeline(
                request.query, 
                days_back=30
            )
        else:
            # ì¼ë°˜ í…ìŠ¤íŠ¸ ê²€ìƒ‰ (ì œëª©, ë‚´ìš©)
            results = search_content(request.query, request.limit)
        
        return {
            "success": True,
            "query": request.query,
            "search_type": request.search_type,
            "result_count": len(results) if isinstance(results, list) else 1,
            "data": results
        }
        
    except Exception as e:
        logger.error(f"ê²€ìƒ‰ ì˜¤ë¥˜: {e}")
        raise HTTPException(status_code=500, detail=f"ê²€ìƒ‰ ì˜¤ë¥˜: {str(e)}")

@app.get("/api/v1/data/recent")
async def get_recent_threats(limit: int = 100, source_type: str = None):
    """
    DíŒŒíŠ¸ìš© ìµœì‹  ìœ„í˜‘ì •ë³´ ì¡°íšŒ
    """
    try:
        import sqlite3
        conn = sqlite3.connect(DB_PATH)
        cursor = conn.cursor()
        
        if source_type:
            cursor.execute('''
                SELECT id, title, text, author, found_at, source_type, threat_type, 
                        event_id, event_info
                FROM threat_posts 
                WHERE source_type = ?
                ORDER BY created_at DESC 
                LIMIT ?
            ''', (source_type, limit))
        else:
            cursor.execute('''
                SELECT id, title, text, author, found_at, source_type, threat_type,
                        event_id, event_info
                FROM threat_posts 
                ORDER BY created_at DESC 
                LIMIT ?
            ''', (limit,))
        
        posts = cursor.fetchall()
        conn.close()
        
        results = []
        for post in posts:
            result_item = {  
                "id": post[0],
                "title": post[1],
                "text": post[2][:200] + "..." if len(post[2]) > 200 else post[2],
                "author": post[3],
                "found_at": post[4],
                "source_type": post[5],
                "threat_type": post[6]
            }  
    
            # ğŸ†• MISP ë°ì´í„°ì¸ ê²½ìš° ì¶”ê°€ ì •ë³´ í¬í•¨
            if post[5] == 'misp':
                result_item.update({
                    "event_id": post[7],
                    "event_info": post[8]
                })
    
            results.append(result_item)
        
        return {
            "success": True,
            "data": results,
            "count": len(results)
        }
        
    except Exception as e:
        logger.error(f"ìµœì‹  ë°ì´í„° ì¡°íšŒ ì˜¤ë¥˜: {e}")
        raise HTTPException(status_code=500, detail=f"ë°ì´í„° ì¡°íšŒ ì˜¤ë¥˜: {str(e)}")

@app.get("/api/v1/data/export/db")
async def export_database():
    """
    DíŒŒíŠ¸ìš© ë°ì´í„°ë² ì´ìŠ¤ íŒŒì¼ ë‹¤ìš´ë¡œë“œ
    """
    try:
        if os.path.exists(DB_PATH):
            return FileResponse(
                DB_PATH,
                media_type='application/octet-stream',
                filename=f"threat_db_{datetime.now().strftime('%Y%m%d_%H%M%S')}.db"
            )
        else:
            raise HTTPException(status_code=404, detail="ë°ì´í„°ë² ì´ìŠ¤ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤")
    except Exception as e:
        logger.error(f"DB ë‚´ë³´ë‚´ê¸° ì˜¤ë¥˜: {e}")
        raise HTTPException(status_code=500, detail=f"ë‚´ë³´ë‚´ê¸° ì˜¤ë¥˜: {str(e)}")

# =============================================================================
# í—¬í¼ í•¨ìˆ˜ë“¤
# =============================================================================

async def process_uploaded_file(file_path: str, source: str, original_filename: str):
    """
    ì—…ë¡œë“œëœ íŒŒì¼ì„ ë°±ê·¸ë¼ìš´ë“œì—ì„œ ì²˜ë¦¬
    """
    try:
        logger.info(f"ë°±ê·¸ë¼ìš´ë“œ ì²˜ë¦¬ ì‹œì‘: {original_filename}")
        
        # íŒŒì¼ ì²˜ë¦¬
        result = normalizer.process_file(file_path, save_to_db=True)
        
        # ì„ì‹œ íŒŒì¼ ì‚­ì œ
        os.unlink(file_path)
        
        if result['status'] == 'SUCCESS':
            logger.info(f"ë°±ê·¸ë¼ìš´ë“œ ì²˜ë¦¬ ì™„ë£Œ: {original_filename} - {result['normalized_count']}ê°œ í•­ëª©")
        else:
            logger.error(f"ë°±ê·¸ë¼ìš´ë“œ ì²˜ë¦¬ ì‹¤íŒ¨: {original_filename} - {result.get('error', 'Unknown error')}")
            
    except Exception as e:
        logger.error(f"ë°±ê·¸ë¼ìš´ë“œ ì²˜ë¦¬ ì˜¤ë¥˜ {original_filename}: {e}")

def search_content(query: str, limit: int = 100) -> List[Dict]:
    """
    ì œëª©, ë‚´ìš©ì—ì„œ í…ìŠ¤íŠ¸ ê²€ìƒ‰
    """
    import sqlite3
    conn = sqlite3.connect(DB_PATH)
    cursor = conn.cursor()
    
    cursor.execute('''
        SELECT id, title, text, author, found_at, source_type
        FROM threat_posts 
        WHERE title LIKE ? OR text LIKE ?
        ORDER BY created_at DESC 
        LIMIT ?
    ''', (f'%{query}%', f'%{query}%', limit))
    
    posts = cursor.fetchall()
    conn.close()
    
    results = []
    for post in posts:
        results.append({
            "id": post[0],
            "title": post[1],
            "text": post[2][:300] + "..." if len(post[2]) > 300 else post[2],
            "author": post[3],
            "found_at": post[4],
            "source_type": post[5]
        })
    
    return results

# =============================================================================
# ì„œë²„ ì‹¤í–‰ ë° ìƒíƒœ í™•ì¸
# =============================================================================

@app.get("/")
async def root():
    """
    API ì„œë²„ ìƒíƒœ í™•ì¸
    """
    return {
        "service": "ìœ„í˜‘ì •ë³´ ë°ì´í„° ì •ì œ API",
        "version": "1.0.0",
        "status": "running",
        "timestamp": get_kst_time(),
        "endpoints": {
            "AíŒŒíŠ¸_BíŒŒíŠ¸ìš©": {
                "JSONíŒŒì¼ì—…ë¡œë“œ": "/api/v1/data/upload/json",
                "ëŒ€ëŸ‰ë°ì´í„°ì „ì†¡": "/api/v1/data/upload/bulk",
                "ë‹¨ì¼ë°ì´í„°ì „ì†¡": "/api/v1/data/upload/single"
            },
            "DíŒŒíŠ¸ìš©": {
                "í†µê³„ì¡°íšŒ": "/api/v1/data/stats",
                "ë°ì´í„°ê²€ìƒ‰": "/api/v1/data/search",
                "ìµœì‹ ë°ì´í„°": "/api/v1/data/recent",
                "DBë‹¤ìš´ë¡œë“œ": "/api/v1/data/export/db"
            }
        }
    }

@app.get("/health")
async def health_check():
    """
    í—¬ìŠ¤ ì²´í¬
    """
    try:
        stats = normalizer.get_database_stats()
        return {
            "status": "healthy",
            "database": "connected",
            "total_posts": stats.get('total_posts', 0),
            "timestamp": get_kst_time()
        }
    except Exception as e:
        return {
            "status": "unhealthy",
            "error": str(e),
            "timestamp": get_kst_time()
        }
@app.post("/api/v1/admin/fix-timezone")
async def fix_timezone():
    """ê¸°ì¡´ ë°ì´í„°ì˜ ì‹œê°„ëŒ€ë¥¼ KSTë¡œ ìˆ˜ì • (1íšŒì„±)"""
    try:
        import sqlite3
        conn = sqlite3.connect(DB_PATH)
        cursor = conn.cursor()
        
        # ë¨¼ì € í˜„ì¬ ë°ì´í„° í™•ì¸
        cursor.execute("SELECT id, created_at FROM threat_posts LIMIT 3")
        sample_data = cursor.fetchall()
        logger.info(f"ìƒ˜í”Œ ë°ì´í„°: {sample_data}")
        
        # ë” ê°•ë ¥í•œ ì—…ë°ì´íŠ¸ ì¿¼ë¦¬ (í˜•ì‹ ìƒê´€ì—†ì´)
        update_queries = [
            # threat_posts í…Œì´ë¸”
            """UPDATE threat_posts 
               SET created_at = datetime(julianday(created_at) + 0.375)
               WHERE created_at IS NOT NULL""",
            
            """UPDATE threat_posts 
               SET date = datetime(julianday(date) + 0.375)
               WHERE date IS NOT NULL AND date != ''""",
            
            """UPDATE threat_posts 
               SET found_at = datetime(julianday(found_at) + 0.375)
               WHERE found_at IS NOT NULL AND found_at != ''""",
            
            # threat_iocs í…Œì´ë¸”
            """UPDATE threat_iocs 
               SET first_seen = datetime(julianday(first_seen) + 0.375)
               WHERE first_seen IS NOT NULL""",
            
            # post_relationships í…Œì´ë¸”
            """UPDATE post_relationships 
               SET created_at = datetime(julianday(created_at) + 0.375)
               WHERE created_at IS NOT NULL""",
            
            # processing_statistics í…Œì´ë¸”
            """UPDATE processing_statistics 
               SET processed_at = datetime(julianday(processed_at) + 0.375)
               WHERE processed_at IS NOT NULL"""
        ]
        
        total_affected = 0
        for i, query in enumerate(update_queries):
            cursor.execute(query)
            affected = cursor.rowcount
            total_affected += affected
            logger.info(f"ì¿¼ë¦¬ {i+1}: {affected}í–‰ ìˆ˜ì •")
        
        conn.commit()
        
        # ìˆ˜ì • í›„ ë°ì´í„° í™•ì¸
        cursor.execute("SELECT id, created_at FROM threat_posts LIMIT 3")
        updated_data = cursor.fetchall()
        logger.info(f"ìˆ˜ì • í›„ ë°ì´í„°: {updated_data}")
        
        conn.close()
        
        return {
            "success": True, 
            "message": f"ì´ {total_affected}ê°œ ë ˆì½”ë“œì˜ ì‹œê°„ì„ KSTë¡œ ìˆ˜ì •í–ˆìŠµë‹ˆë‹¤",
            "affected_rows": total_affected,
            "sample_before": sample_data,
            "sample_after": updated_data
        }
        
    except Exception as e:
        logger.error(f"ì‹œê°„ëŒ€ ìˆ˜ì • ì˜¤ë¥˜: {e}")
        raise HTTPException(status_code=500, detail=f"ì‹œê°„ëŒ€ ìˆ˜ì • ì˜¤ë¥˜: {str(e)}")

@app.post("/api/v1/test/create-dummy")
async def create_dummy_data():
    """ì˜êµ¬ ì €ì¥ì†Œ í…ŒìŠ¤íŠ¸ìš©"""
    try:
        import sqlite3
        conn = sqlite3.connect(DB_PATH)
        cursor = conn.cursor()
        
        cursor.execute('''
            INSERT INTO threat_posts 
            (id, source_type, title, text, author, created_at)
            VALUES (?, ?, ?, ?, ?, datetime('now', 'localtime'))
        ''', ('test-persist-001', 'test', 'Persistence Test', 'This data should survive redeployment', 'test_user'))
        
        conn.commit()
        conn.close()
        
        return {"success": True, "message": "í…ŒìŠ¤íŠ¸ ë°ì´í„° ìƒì„± ì™„ë£Œ", "db_path": DB_PATH}
    except Exception as e:
        return {"success": False, "error": str(e)}

# =============================================================================
# ì„œë²„ ì‹¤í–‰ ìŠ¤í¬ë¦½íŠ¸
# =============================================================================

if __name__ == "__main__":
    import uvicorn
    
    # ë°ì´í„°ë² ì´ìŠ¤ ì´ˆê¸°í™”
    threat_processor.init_advanced_database()
    
    print("=== ìœ„í˜‘ì •ë³´ ë°ì´í„° ì •ì œ API ì„œë²„ ===")
    print("AíŒŒíŠ¸(ë‹¤í¬ì›¹), BíŒŒíŠ¸(í…”ë ˆê·¸ë¨) â†’ CíŒŒíŠ¸(ì •ì œ) â†’ DíŒŒíŠ¸(ëŒ€ì‹œë³´ë“œ)")
    print()
    print("ì„œë²„ ì£¼ì†Œ: http://localhost:8000")
    print("API ë¬¸ì„œ: http://localhost:8000/docs")
    print("í—¬ìŠ¤ ì²´í¬: http://localhost:8000/health")
    print()
    
    # ì„œë²„ ì‹¤í–‰
    uvicorn.run(
        "threat_api_server:app",  # ì´ íŒŒì¼ëª…ì´ threat_api_server.pyë¼ê³  ê°€ì •
        host="0.0.0.0",
        port=8000,
        reload=True,  # ê°œë°œ ì¤‘ì—ëŠ” True, í”„ë¡œë•ì…˜ì—ì„œëŠ” False
        log_level="info"
    )